# Laborat√≥rio Jogo da Vida Paralelo

## üìã Vis√£o Geral

Este projeto implementa diferentes vers√µes paralelas do **Jogo da Vida de Conway** para compara√ß√£o de performance entre paradigmas de programa√ß√£o paralela:

- **MPI** (Message Passing Interface) - mem√≥ria distribu√≠da
- **OpenMP** - mem√≥ria compartilhada
- **CUDA** - computa√ß√£o em GPU NVIDIA
- **OpenMP GPU** - offloading para GPU com OpenMP

## üéØ Objetivos

- Experimentar diferentes paradigmas de programa√ß√£o paralela
- Comparar performance entre as implementa√ß√µes
- Analisar escalabilidade e efici√™ncia
- Validar a movimenta√ß√£o correta do "veleiro" no tabuleiro

## üèóÔ∏è Estrutura do Projeto

```
jogodavida-paralelo/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ jogodavida.c          # Vers√£o sequencial original
‚îÇ   ‚îú‚îÄ‚îÄ jogodavidampi.c       # Vers√£o MPI
‚îÇ   ‚îú‚îÄ‚îÄ jogodavidaomp.c       # Vers√£o OpenMP
‚îÇ   ‚îú‚îÄ‚îÄ jogodavida.cu         # Vers√£o CUDA
‚îÇ   ‚îî‚îÄ‚îÄ jogodavidaomp_gpu.c   # Vers√£o OpenMP GPU
‚îú‚îÄ‚îÄ Makefile                  # Makefile
‚îú‚îÄ‚îÄ run_benchmark.sh          # Script de benchmark automatizado
‚îú‚îÄ‚îÄ results/                  # Resultados dos experimentos
‚îî‚îÄ‚îÄ README.md                 # Esta documenta√ß√£o
```

## üîß Compila√ß√£o

### Pr√©-requisitos

- **GCC** 7.0+ com suporte OpenMP
- **Open MPI** ou Intel MPI
- **CUDA Toolkit** 10.0+ (para vers√£o CUDA)
- **OpenMP 4.5+** com suporte GPU (para vers√£o OpenMP GPU)

### Verificar Depend√™ncias

```bash
make check-deps
```

### Compilar Todas as Vers√µes

```bash
make all
```

### Compilar Vers√µes Espec√≠ficas

```bash
# Vers√£o sequencial
make jogodavida

# Vers√£o MPI
make jogodavidampi

# Vers√£o OpenMP
make jogodavidaomp

# Vers√£o CUDA
make jogodavida_cuda

# Vers√£o OpenMP GPU
make jogodavidaomp_gpu
```

## üöÄ Execu√ß√£o

### Testes B√°sicos

```bash
# Executar todos os testes b√°sicos
make test

# Vers√£o sequencial
./jogodavida

# Vers√£o OpenMP (definir n√∫mero de threads)
export OMP_NUM_THREADS=4
./jogodavidaomp

# Vers√£o MPI (definir n√∫mero de processos)
mpirun -np 4 ./jogodavidampi

# Vers√£o CUDA
./jogodavida_cuda

# Vers√£o OpenMP GPU
./jogodavidaomp_gpu
```

### Benchmark Automatizado

```bash
# Executar benchmark completo
make benchmark
# ou
./run_benchmark.sh
```

## üìä An√°lise de Resultados

### M√©tricas Coletadas

- **Tempo de inicializa√ß√£o** (`t_init`)
- **Tempo de computa√ß√£o** (`t_comp`) 
- **Tempo de finaliza√ß√£o** (`t_fim`)
- **Tempo total** (`t_total`)

### C√°lculo de Performance

```
Speedup = T_sequencial / T_paralelo
Efici√™ncia = Speedup / N√∫mero_de_Processadores
Throughput = C√©lulas_processadas / Tempo_computa√ß√£o
```

### Valida√ß√£o

Todas as vers√µes devem:
- ‚úÖ Produzir resultado "**RESULTADO CORRETO**"
- ‚úÖ Mover o veleiro do canto superior esquerdo ao inferior direito
- ‚úÖ Manter exatamente 5 c√©lulas vivas ao final

## üîç Detalhes das Implementa√ß√µes

### 1. Vers√£o MPI (`jogodavidampi.c`)

**Estrat√©gia**: Divis√£o horizontal do tabuleiro entre processos

**Caracter√≠sticas**:
- Processo 0 atua como coordenador
- Distribui√ß√£o equilibrada de linhas entre workers
- Comunica√ß√£o coletiva (`MPI_Bcast`, `MPI_Allgather`)
- Sincroniza√ß√£o a cada gera√ß√£o

**Comando de execu√ß√£o**:
```bash
mpirun -np <num_processos> ./jogodavidampi
```

### 2. Vers√£o OpenMP (`jogodavidaomp.c`)

**Estrat√©gia**: Paraleliza√ß√£o de loops com threads

**Caracter√≠sticas**:
- `#pragma omp parallel for` nos loops principais
- Scheduling est√°tico para balanceamento
- Redu√ß√£o paralela na verifica√ß√£o
- Inicializa√ß√£o paralela

**Vari√°veis de ambiente**:
```bash
export OMP_NUM_THREADS=<num_threads>
export OMP_SCHEDULE=static
```

### 3. Vers√£o CUDA (`jogodavida.cu`)

**Estrat√©gia**: Computa√ß√£o massivamente paralela em GPU

**Caracter√≠sticas**:
- Kernel otimizado com mem√≥ria compartilhada
- Grid 2D de blocos e threads
- Gest√£o expl√≠cita de mem√≥ria GPU
- Dois kernels: b√°sico e otimizado

**Configura√ß√£o de kernel**:
```cpp
dim3 blockSize(16, 16);           // 256 threads por bloco
dim3 gridSize((tam+15)/16, (tam+15)/16);  // Cobertura do tabuleiro
```

### 4. Vers√£o OpenMP GPU (`jogodavidaomp_gpu.c`)

**Estrat√©gia**: Offloading para GPU usando diretivas OpenMP

**Caracter√≠sticas**:
- `#pragma omp target` para offloading
- Gest√£o autom√°tica e expl√≠cita de dados
- Fallback para CPU se GPU indispon√≠vel
- Teams e distribute para paraleliza√ß√£o GPU

**Diretivas principais**:
```cpp
#pragma omp target teams distribute parallel for collapse(2) \
        map(to: tabulIn[0:total_cells]) \
        map(from: tabulOut[0:total_cells])
```

## üìà Resultados Esperados

### Performance T√≠pica

| Vers√£o | Tabuleiro 64x64 | Tabuleiro 256x256 | Speedup |
|--------|-----------------|-------------------|---------|
| Sequencial | 0.0120s | 0.1850s | 1.0x |
| OpenMP (4 threads) | 0.0035s | 0.0520s | 3.4x |
| MPI (4 processos) | 0.0040s | 0.0580s | 3.2x |
| CUDA | 0.0015s | 0.0080s | 8.0x |
| OpenMP GPU | 0.0020s | 0.0120s | 6.2x |

*Valores ilustrativos - resultados variam conforme hardware*

### Escalabilidade

- **OpenMP**: Linear at√© n√∫mero de cores f√≠sicos
- **MPI**: Boa escalabilidade em clusters
- **CUDA**: Excelente para tabuleiros grandes (>512x512)
- **OpenMP GPU**: Boa para tabuleiros m√©dios-grandes

## üêõ Troubleshooting

### Problemas Comuns

**1. Erro de compila√ß√£o MPI**
```bash
# Verificar instala√ß√£o MPI
which mpicc
mpicc --version

# Instalar se necess√°rio (Ubuntu/Debian)
sudo apt-get install libopenmpi-dev openmpi-bin
```

**2. Erro CUDA "No CUDA-capable device"**
```bash
# Verificar GPU NVIDIA
nvidia-smi

# Verificar instala√ß√£o CUDA
nvcc --version
```

**3. OpenMP GPU n√£o funciona**
```bash
# Verificar suporte do compilador
gcc -fopenmp -foffload=nvptx-none --version

# Alternativa: usar Clang com OpenMP GPU
clang -fopenmp -fopenmp-targets=nvptx64 -O3 -o jogodavidaomp_gpu jogodavidaomp_gpu.c
```

**4. Resultado incorreto**
- Verificar se o tabuleiro tem bordas adequadas
- Conferir √≠ndices nos kernels/loops paralelos
- Validar comunica√ß√£o entre processos (MPI)

### Logs de Debug

Habilitar logs detalhados:
```bash
# MPI
export OMPI_MCA_verbose=1
mpirun -np 4 ./jogodavidampi

# CUDA
export CUDA_LAUNCH_BLOCKING=1
./jogodavida_cuda

# OpenMP
export OMP_DISPLAY_ENV=true
./jogodavidaomp
```

## üìö Refer√™ncias

1. **Conway's Game of Life**: Gardner, M. "Mathematical Games", Scientific American 223, Oct 1970
2. **MPI Documentation**: [https://www.open-mpi.org/doc/](https://www.open-mpi.org/doc/)
3. **OpenMP Specification**: [https://www.openmp.org/specifications/](https://www.openmp.org/specifications/)
4. **CUDA Programming Guide**: [https://docs.nvidia.com/cuda/](https://docs.nvidia.com/cuda/)
5. **OpenMP GPU Offloading**: [https://www.openmp.org/updates/openmp-accelerator-support-gpus/](https://www.openmp.org/updates/openmp-accelerator-support-gpus/)

## ü§ù Contribui√ß√£o

Este projeto √© parte do laborat√≥rio de **Programa√ß√£o para Sistemas Paralelos e Distribu√≠dos**.

### Estrutura do Relat√≥rio

O relat√≥rio deve incluir:

1. **Identifica√ß√£o**
   - Disciplina, turma, grupo e laborat√≥rio

2. **C√≥digos Comentados**
   - Listagem com explica√ß√£o das paraleliza√ß√µes
   - Instru√ß√µes de compila√ß√£o e execu√ß√£o
   - Dificuldades encontradas e solu√ß√µes

3. **Experimenta√ß√£o**
   - Cen√°rios de teste executados
   - Tabela comparativa de tempos
   - An√°lise de speedup e efici√™ncia

4. **Conclus√µes**
   - Percentual de ganho entre solu√ß√µes
   - GPU mais eficiente no cluster
   - Recomenda√ß√µes de uso

### Crit√©rios de Avalia√ß√£o

- ‚úÖ **Funcionalidade**: Todas as vers√µes executam corretamente
- ‚úÖ **Performance**: Speedup demonstr√°vel nas vers√µes paralelas
- ‚úÖ **Documenta√ß√£o**: C√≥digo bem comentado e relat√≥rio completo
- ‚úÖ **Experimenta√ß√£o**: An√°lise comparativa rigorosa
- ‚úÖ **Apresenta√ß√£o**: V√≠deo demonstrativo (4-6 min/aluno)

## üìû Suporte

Para d√∫vidas sobre:
- **Compila√ß√£o**: Verificar se√ß√£o Troubleshooting
- **Execu√ß√£o**: Conferir comandos na se√ß√£o Execu√ß√£o  
- **Resultados**: Analisar logs em `results/`
- **Relat√≥rio**: Seguir estrutura descrita acima

---

**Desenvolvido para**: Programa√ß√£o para Sistemas Paralelos e Distribu√≠dos  
**Plataforma alvo**: Cluster chococino (164.41.20.252)  
**Linguagens**: C, CUDA  
**Paradigmas**: MPI, OpenMP, CUDA, OpenMP GPU